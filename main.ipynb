{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether there are missing values `b.i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"loan_old.csv\")\n",
    "empty = df.isnull().sum().sum()\n",
    "print(\"There are \" + str(empty) + \" empty values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Records containing missing values are removed `c.i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    clean_df = df.drop(columns=[\"Loan_ID\"]) # No need for id as well\n",
    "    clean_df = clean_df.dropna()\n",
    "    return clean_df\n",
    "\n",
    "clean_df = preprocess_df(df)\n",
    "display(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the type of each feature, and the scale of numerical features (implies separating the features and the targets)\n",
    "`b.ii`, `b.iii`, `c.ii`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = clean_df.drop(columns=[\"Max_Loan_Amount\", \"Loan_Status\"])\n",
    "targets_df = clean_df[[\"Max_Loan_Amount\", \"Loan_Status\"]]\n",
    "\n",
    "categorical_features_df = features_df.select_dtypes(include=[\"object\"])\n",
    "numerical_features_df = features_df.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "print(\"Categorical features:\")\n",
    "for col in categorical_features_df.columns:\n",
    "    print(f\"\\t- {col}\")\n",
    "print(\"Numerical features:\")\n",
    "for col in numerical_features_df.columns:\n",
    "    print(\n",
    "        f\"\\t- {col} ({numerical_features_df[col].min()} - {numerical_features_df[col].max()})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a pairplot between numerical columns `b.iv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(clean_df.select_dtypes(exclude=[\"object\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is shuffled and split into training and testing sets `c.iii`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "train_size = 1 - test_size\n",
    "\n",
    "(\n",
    "    features_train,\n",
    "    features_test,\n",
    "    max_loan_train,\n",
    "    max_loan_test,\n",
    "    loan_status_train,\n",
    "    loan_status_test,\n",
    ") = train_test_split(\n",
    "    features_df,\n",
    "    targets_df[\"Max_Loan_Amount\"],\n",
    "    targets_df[\"Loan_Status\"],\n",
    "    test_size=test_size,\n",
    "    train_size=train_size,\n",
    "    random_state=30,\n",
    ")\n",
    "\n",
    "print(\"Features training set\")\n",
    "display(features_train)\n",
    "print(\"Features testing set\")\n",
    "display(features_test)\n",
    "print(\"Max loan (target) training\")\n",
    "display(pd.DataFrame(max_loan_train))\n",
    "print(\"Max loan (target) testing\")\n",
    "display(pd.DataFrame(max_loan_test))\n",
    "print(\"Loan status (target) training\")\n",
    "display(pd.DataFrame(loan_status_train))\n",
    "print(\"Loan status (target) testing\")\n",
    "display(pd.DataFrame(loan_status_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data:\n",
    "- Categorical features are encoded `c.iv`\n",
    "- Numerical features are standardized `c.vi`\n",
    "- Categorical targets are encoded `c.v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "standard_scalers = {}\n",
    "processed_features_train = pd.DataFrame()\n",
    "\n",
    "for col in features_train.columns:\n",
    "    if features_train[col].dtype == \"object\":\n",
    "        print(f\"Encoding {col}\")\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        processed_features_train[col] = label_encoders[col].fit_transform(features_train[col])\n",
    "        print(f\"\\t- Before: {label_encoders[col].classes_}\")\n",
    "        print(f\"\\t- After: {np.unique(processed_features_train[col])}\")\n",
    "    else:\n",
    "        print(f\"Standardizing {col}\")\n",
    "        print(\n",
    "            f\"\\t- Before: {np.min(features_train[col])} to {np.max(features_train[col])}\"\n",
    "        )\n",
    "        standard_scalers[col] = StandardScaler()\n",
    "        processed_features_train[col] = standard_scalers[col].fit_transform(features_train[[col]])\n",
    "        print(\n",
    "            f\"\\t- After: {np.min(processed_features_train[col])} to {np.max(processed_features_train[col])}\"\n",
    "        )\n",
    "\n",
    "print(f\"Encoding training Loan_Status\")\n",
    "loan_status_encoder = LabelEncoder()\n",
    "processed_loan_status_train = pd.Series(\n",
    "    loan_status_encoder.fit_transform(loan_status_train),\n",
    "    name=loan_status_train.name,\n",
    ")\n",
    "print(f\"\\t- Before: {loan_status_encoder.classes_}\")\n",
    "print(f\"\\t- After: {np.unique(processed_loan_status_train)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a linear regression model to the data to predict the loan amount. `d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(processed_features_train, max_loan_train)\n",
    "print(linear_model.feature_names_in_)\n",
    "print(linear_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the linear regression model using sklearn's R2 score. `e`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_features_test = pd.DataFrame()\n",
    "\n",
    "for col in features_test.columns:\n",
    "    if features_test[col].dtype == \"object\":\n",
    "        print(f\"Encoding {col}\")\n",
    "        processed_features_test[col] = label_encoders[col].transform(features_test[col])\n",
    "        print(f\"\\t- Before: {label_encoders[col].classes_}\")\n",
    "        print(f\"\\t- After: {np.unique(processed_features_test[col])}\")\n",
    "    else:\n",
    "        print(f\"Standardizing {col}\")\n",
    "        print(\n",
    "            f\"\\t- Before: {np.min(features_test[col])} to {np.max(features_test[col])}\"\n",
    "        )\n",
    "        processed_features_test[col] = standard_scalers[col].transform(features_test[[col]])\n",
    "        print(\n",
    "            f\"\\t- After: {np.min(processed_features_test[col])} to {np.max(processed_features_test[col])}\"\n",
    "        )\n",
    "\n",
    "print(f\"R^2 score: {linear_model.score(processed_features_test, max_loan_test)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
